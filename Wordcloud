library(tm)
library(wordcloud)

###LOAD DF###
df <- read.csv("x.csv", stringsAsFactors = FALSE)
setwd("y")


# Create corpus for HEADLINES
corpus=Corpus(VectorSource(df$Title))

# Convert to lower-case, remove punctuation, remove numbers
corpus=tm_map(corpus,tolower)
corpus=tm_map(corpus, removePunctuation)
corpus=tm_map(corpus, removeNumbers)

# Remove stopwords
corpus=tm_map(corpus,function(x) removeWords(x,stopwords()))
corpus=tm_map(corpus, removeWords, c("cnn", "npr", "cnncom", "cnnpoliticscom", "says", "can", "may", "will", "get", "know", "say", "one", "report", 
                                     "fast", "back", "case", "big", "study", "new", "opinion", "review", "first", "year", "said", "just", "like", 
                                     "make", "see", "going", "still", "according", "made", "take", "told", "take", "many", "even", "also", "two", 
                                     "three", "much", "way", "dont", "thats", "another", "since", "around", "including", "really", "found",
                                     "last", "called"))

# convert corpus to a Plain Text Document
corpus=tm_map(corpus,PlainTextDocument)

#CREATE WORDCLOUD
col=brewer.pal(6,"Dark2")
wordcloud(corpus, min.freq=25, scale=c(5,2),rot.per = 0.25,
          random.color=T, max.word=45, random.order=F,colors=col)


#TERM FREQUENCY
corpusPTD <- tm_map(corpus, PlainTextDocument)
dtm <- DocumentTermMatrix(corpusPTD)
termFreq <- colSums(as.matrix(dtm))

tf <- data.frame(term = names(termFreq), freq = termFreq)
tf <- tf[order(-tf[,2]),]
head(tf, n = 25)


